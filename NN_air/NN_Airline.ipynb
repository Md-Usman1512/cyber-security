{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Satisfaction in Airline Data\n",
    "## With Neural-Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "Neural Networks (NNs) (nowadays also known as deep learning (DL)) are at the heart of modern machine learning. They have been used successfully at solving some of the most challenging machine learning problems in the world including image and video recognition, speech recognition, and generative adversarial network problems. Despite their superior performance, NNs have several drawbacks:\n",
    "- They usually require a lot of data to perform well.\n",
    "- They are black box models and their results are almost impossible to explain.\n",
    "- The math behind NNs is complicated and not easy to grasp for many people.\n",
    "- For the \"wrong\" type of problem, they can overfit like crazy.\n",
    "- Training NNs can become mathematically challenging due to this so-called vanishing gradient phenomena.\n",
    "- NNs have a huge number of hyperparameters to fine tune.\n",
    "- Fine tuning NNs is notoriously difficult and challenging and it can make your life miserable (seriously).\n",
    "\n",
    "On the other hand, NNs can be the preferred tool in the following cases:\n",
    "- You have lots of data.\n",
    "- You data contains little nuances that is hard to be recognized by the more conventional ML methods.\n",
    "- You have lots of numerical features.\n",
    "- Your target feature is numeric (though NNs also work well for classification problems).\n",
    "\n",
    "Thus, NNs can be considered as specialized tools for specific purposes. For some of problems in the real-world that do not involve image/ video/ speech recognition, you might be better off by staying away from them. On the other hand, you should never underestimate the power of a carefully fine-tuned NN. So, it really depends.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "The objective of this notebook is to model the `Airline passenger Satisfaction` case study, which is a binary classification problem, using neural networks. Even though it can be challenging to grasp how NNs work, **you do not really need to know in full details how things work behind the scenes**. Instead, you can stick to good practices for tuning them and have a look at its cross-validated performance.\n",
    "\n",
    "We need to warn you that this notebook barely scratches the surface of NN/ DLs and it will be very brief. Its purpose is to give you a headstart in case you would like to experiment with NN/ DLs sometime in your career in the future.\n",
    "\n",
    "### Packages\n",
    "\n",
    "You will need to install `tensorflow` (Google's deep learning software library) and its `keras` interface as shown below. These two are by far the two most popular DL tools out there at the moment.\n",
    "\n",
    "```Python\n",
    "pip install tensorflow\n",
    "pip install keras\n",
    "```\n",
    "\n",
    "The good news is, even though NNs are hard to work with in general, `tensorflow` and `keras` together make this process as simple as it can possibly be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0: Modeling Preparation\n",
    "\n",
    "- Read in the data `clean_phase1_df.csv`. \n",
    "- Encode categorical variables with `One-Hot-Encoding` (Except target)\n",
    "- You will split the sampled data as 80% training set and the remaining 20% **validation** (not test!) set using a random seed of 999. However, you will use the name \"test\" for naming variables to be consistent with the previous tutorials.\n",
    "- Define the `overall_satisfaction` column as the `target` column\n",
    "- Remember to separate `target` during the splitting process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# so that we can see all the columns\n",
    "pd.set_option('display.max_columns', None) \n",
    "\n",
    "# setup matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 22)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "\n",
    "# so that we can see all the columns\n",
    "pd.set_option('display.max_columns', None) \n",
    "\n",
    "df = pd.read_csv('clean_phase1_df')\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We dont want the target to be One-Hot encoded so apply a mapper\n",
    "df['overall_satisfaction'] = df['overall_satisfaction'].map({'satisfied': 1, 'neutral or dissatisfied': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values for gender\n",
      "['Male' 'Female']\n",
      "\n",
      "Unique values for customer_type\n",
      "['Loyal Customer' 'disloyal Customer']\n",
      "\n",
      "Unique values for travel_type\n",
      "['Personal Travel' 'Business travel']\n",
      "\n",
      "Unique values for customer_class\n",
      "['Eco' 'Business' 'Eco Plus']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categoricalColumns = df.columns[df.dtypes==object].tolist()\n",
    "for col in categoricalColumns:\n",
    "    print('Unique values for ' + col)\n",
    "    print(df[col].unique())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some categorical attributes contain excessive white spaces, which makes life hard when filtering data. We will apply the `strip()` function to remove extra white spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categoricalColumns:\n",
    "    df[col] = df[col].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code chunk below, we first use the `get_dummies()` function in `Pandas` for one-hot-encoding of categorical features and then we construct a new formula string with the encoded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>flight_distance</th>\n",
       "      <th>wifi_service</th>\n",
       "      <th>depart_arrive_time</th>\n",
       "      <th>online_booking</th>\n",
       "      <th>gate_location</th>\n",
       "      <th>food_drink</th>\n",
       "      <th>online_boarding</th>\n",
       "      <th>seat_comfort</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>onboard_service</th>\n",
       "      <th>legroom_service</th>\n",
       "      <th>baggage_handle</th>\n",
       "      <th>checkin_service</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>departure_delay</th>\n",
       "      <th>arrival_delay</th>\n",
       "      <th>overall_satisfaction</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>customer_type_disloyal Customer</th>\n",
       "      <th>travel_type_Personal Travel</th>\n",
       "      <th>customer_class_Eco</th>\n",
       "      <th>customer_class_Eco Plus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81298</th>\n",
       "      <td>21</td>\n",
       "      <td>760</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115157</th>\n",
       "      <td>38</td>\n",
       "      <td>651</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45666</th>\n",
       "      <td>37</td>\n",
       "      <td>1199</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92208</th>\n",
       "      <td>17</td>\n",
       "      <td>964</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98288</th>\n",
       "      <td>38</td>\n",
       "      <td>2938</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  flight_distance  wifi_service  depart_arrive_time  \\\n",
       "81298    21              760             1                   3   \n",
       "115157   38              651             2                   1   \n",
       "45666    37             1199             3                   3   \n",
       "92208    17              964             1                   1   \n",
       "98288    38             2938             3                   3   \n",
       "\n",
       "        online_booking  gate_location  food_drink  online_boarding  \\\n",
       "81298                1              3           2                1   \n",
       "115157               1              1           1                4   \n",
       "45666                2              3           2                4   \n",
       "92208                1              5           3                1   \n",
       "98288                3              3           4                4   \n",
       "\n",
       "        seat_comfort  entertainment  onboard_service  legroom_service  \\\n",
       "81298              2              2                3                2   \n",
       "115157             3              2                2                2   \n",
       "45666              5              3                3                2   \n",
       "92208              5              3                1                1   \n",
       "98288              5              5                5                5   \n",
       "\n",
       "        baggage_handle  checkin_service  cleanliness  departure_delay  \\\n",
       "81298                3                2            2                0   \n",
       "115157               2                1            2                0   \n",
       "45666                3                4            1                0   \n",
       "92208                4                4            3                0   \n",
       "98288                5                4            3                0   \n",
       "\n",
       "        arrival_delay  overall_satisfaction  gender_Male  \\\n",
       "81298               0                     0            1   \n",
       "115157              0                     0            0   \n",
       "45666              14                     1            1   \n",
       "92208               5                     0            0   \n",
       "98288               1                     1            0   \n",
       "\n",
       "        customer_type_disloyal Customer  travel_type_Personal Travel  \\\n",
       "81298                                 0                            1   \n",
       "115157                                0                            0   \n",
       "45666                                 0                            0   \n",
       "92208                                 1                            0   \n",
       "98288                                 0                            0   \n",
       "\n",
       "        customer_class_Eco  customer_class_Eco Plus  \n",
       "81298                    1                        0  \n",
       "115157                   0                        0  \n",
       "45666                    0                        0  \n",
       "92208                    1                        0  \n",
       "98288                    0                        0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot-encoding of categorical features\n",
    "# for this to work correctly, variable data types (numeric or categorical)\n",
    "# must be correctly specified within the Pandas dataframe\n",
    "data_encoded = pd.get_dummies(df, drop_first=True)\n",
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Data = data_encoded.drop(columns=['overall_satisfaction'])\n",
    "\n",
    "target = data_encoded['overall_satisfaction'].values.reshape(-1, 1) \n",
    "\n",
    "# scale all columns in X to be between 0 and 1 in case they are not\n",
    "scaler_Data = MinMaxScaler().fit(Data.values)\n",
    "Data_scaled = scaler_Data.transform(Data.values)\n",
    "\n",
    "# you should ALWAYS normalize target as well for neural networks\n",
    "# but for this problem, target is already between 0 and 1 (since it's binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_train, D_test, t_train, t_test, idx_train, idx_test = \\\n",
    "   train_test_split(Data_scaled, target, Data.index, test_size=0.2, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Defining Network Parameters\n",
    "\n",
    "As mentioned earlier, fine tuning NNs is notoriously difficult due to the large number of parameters. For this example, you will use a NN with two hidden layers. This is referred to as the `topology` of the NN. Here is an illustration of a neural network with 3 input features and two hidden layers with 4 neurons in each hidden layer (source: medium.com).\n",
    "\n",
    "<img src=https://miro.medium.com/max/1000/1*3fA77_mLNiJTSgZFhYnU0Q.png width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the hidden layers, you will need to have two more layers:\n",
    "- an input layer (which are the scaled descriptive features) and \n",
    "- an output layer (which is the target feature, i.e., the prediction of the network). \n",
    "\n",
    "Neurons in the hidden layers are nonlinear functions (in general). Via these functions (called activation functions), you are  approximating the output as a highly nonlinear function of the input features. The higher the number of neurons and/ or number of hidden layers, the higher the nonlinearity of the relationship between the input features and the target feature.\n",
    "\n",
    "The size of the network is determined by the number of neurons in each layer. You might want to start small and then make the network bigger until performance stops increasing. As a general guideline, your network should be as small as possible to prevent overfitting on unseen observations. Another practice is that number or neurons in the second layer should not be higher than the first layer.\n",
    "\n",
    "For the hidden layers, in addition to how many neurons you want in each layer, you also need to specify which type of activation function you will use for each of them. For the hidden layers, `relu` is a popular choice, which is short for `rectified linear unit`. You can learn more about these activation functions [here](https://keras.io/activations/). \n",
    "\n",
    "After each hidden layer, you might want to add a `dropout` layer, which has been shown to reduce the chances of overfitting in some cases. For these dropout layers, you will need to specify the dropout rate. However, do not automatically assume dropout is the ultimate solution. Sometimes regularization in the layers might be a better idea; see Keras documentation [here](https://keras.io/regularizers/) for more information.\n",
    "\n",
    "For the output layer, if your problem is binary classification, you will need to use a sigmoid activation function whose output is always between 0 and 1.\n",
    "\n",
    "For the training process, you will need to specify \n",
    "- The number of epochs (that is, training iterations): You will look for an elbow-shaped performance curve to determine the number of epochs. Too big values for this parameter would result in overfitting and too small values in underfitting. So this is a critical parameter to achieve a good balance between over and under fitting.\n",
    "- Batch size (size of data chunk to feed into NN one at a time)\n",
    "\n",
    "For training the network, you will need to specify\n",
    "- The optimization algorithm and its parameters (more info [here](https://keras.io/optimizers/))\n",
    "- Loss function (more info [here](https://keras.io/losses/))\n",
    "- Metrics to monitor during the training (more info [here](https://keras.io/api/metrics/))\n",
    "\n",
    "For this exercise task, you will set the above parameters to specific values. **This is already tuned for this assignment** On the other hand, there is a huge level of interaction between these parameters. Besides, the NN performance can be very sensitive to even small changes in one of the parameters. **That's what makes NN tuning so tedious and difficult.** For instance, the batch size, which might perhaps appear trivial initially, can be absolutely critical in obtaining a satisfactory performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the network is determined by the number of neural units in each hidden layer\n",
    "layer1_units = 4\n",
    "layer2_units = 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 'binary_crossentropy' \n",
    "# during training, we would like to monitor accuracy\n",
    "metrics = ['accuracy'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_activation = 'relu'\n",
    "layer2_activation = 'relu'\n",
    "output_activation = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_dropout_rate = 0.05\n",
    "layer2_dropout_rate = 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01\n",
    "decay=1e-6\n",
    "momentum=0.5\n",
    "# SGD stands for stochastic gradient descent\n",
    "optimizer = SGD(lr=learning_rate, decay=decay, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Setting up the Model\n",
    "\n",
    "The code chunk below sets up the NN model based on the specified input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up an empty deep learning model\n",
    "def model_factory(input_dim, layer1_units, layer2_units):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer1_units, input_dim=input_dim, activation=layer1_activation))\n",
    "    model.add(Dropout(layer1_dropout_rate))\n",
    "    model.add(Dense(layer2_units, activation=layer1_activation))\n",
    "    model.add(Dropout(layer2_dropout_rate))\n",
    "    model.add(Dense(1, activation=output_activation))\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Utility Function for Plotting\n",
    "\n",
    "You will define a function to plot performance of the NN during training. You will plot the performance on both the training data and the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define plot function for the fit\n",
    "# we will plot the accuracy here\n",
    "def plot_history(history): \n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Model Training\n",
    "\n",
    "You are now ready to train your model. If you want to see results at the end of each iteration, set `verbose` to 1. Otherwise keep it at 0 for no details. Keep in mind that, especially for a large number of epochs, **the fitting process can take a lot of time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = model_factory(Data.shape[1], layer1_units, layer2_units)\n",
    "\n",
    "# in the summary, notice the LARGE number of total parameters in the model\n",
    "model_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_test = model_test.fit(D_train, \n",
    "                              t_train,\n",
    "                              epochs=epochs,\n",
    "                              batch_size=batch_size,\n",
    "                              verbose=0, # set to 1 for iteration details, 0 for no details\n",
    "                              shuffle=True,\n",
    "                              validation_data=(D_test, t_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are the keys in the history attribute of the fitted model object\n",
    "history_test.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Plotting Results\n",
    "\n",
    "You will plot the results using our utility plotting function we defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Performance Evaluation\n",
    "\n",
    "You will get the predictions on the validation data and have a look at accuracy and AUC on the validation data. As an exercise, compare the accuracy here to the test accuracy you obtained for the same problem in the SK0 practice notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute prediction performance on test data\n",
    "model_output = model_test.predict(D_test).astype(float)\n",
    "\n",
    "# decide classification based on threshold of 0.5\n",
    "t_pred = np.where(model_output < 0.5, 0, 1)\n",
    "\n",
    "# set up the results data frame\n",
    "result_test = pd.DataFrame()\n",
    "result_test['target'] = t_test.flatten()\n",
    "result_test['fit'] = t_pred\n",
    "# residuals will be relevant for regression problems\n",
    "# result_test['abs_residual'] = np.abs(result_test['target'] - result_test['fit'])\n",
    "result_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(result_test['target'], result_test['fit'])\n",
    "auc = roc_auc_score(result_test['target'], result_test['fit'])\n",
    "print(f\"validation data accuracy_score = {acc:.3f}\")\n",
    "print(f\"validation data roc_auc_score = {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "I tried to apply move a little bit from the statsmodels approach and try to experiment with some machine learning on our dataset. For the sake of simplicity I changet target(dependant) variable from numerical to categorical, to change the problem from regression to classification.\n",
    "Used the most modern and robust libraries and methods and got the better performance than classical (but poor) OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
